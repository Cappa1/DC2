{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn import linear_model\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "import math\n",
    "\n",
    "np.set_printoptions(formatter={'float_kind':'{:f}'.format})\n",
    "pd.set_option('display.float_format', lambda x: '%.3f' % x)\n",
    "plt.style.use('seaborn')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading data and preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data = pd.read_pickle('/home/dazai/Documents/Processmining/Data/pickle.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uncomment the cell below and run it if you dont have a pickle of preprocessed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path = r\"/home/dazai/Documents/Processmining/Data/\"\n",
    "# df_train = pd.read_csv(f'{path}BPI_Challenge_2012-training.csv')\n",
    "# df_test = pd.read_csv(f'{path}BPI_Challenge_2012-test.csv')\n",
    "\n",
    "\n",
    "# df_data = pd.concat([df_train, df_test])\n",
    "# df_data['event time:timestamp'] = pd.to_datetime(df_data['event time:timestamp'], dayfirst=True)\n",
    "# df_data['case REG_DATE'] = pd.to_datetime(df_data['case REG_DATE'])\n",
    "\n",
    "# df_data.sort_values(by=['event time:timestamp'], inplace=True)\n",
    "# df_data.reset_index(inplace=True, drop=True)\n",
    "\n",
    "# # remove whitespace at beginning and end of column name\n",
    "# df_data.columns = df_data.columns.str.strip(' ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sliding_window(window_size, df):\n",
    "    \"\"\"transforms df_data into supervised form \n",
    "    with rolling window implementations\n",
    "\n",
    "    Args:\n",
    "        window_size (int): size of rolling window\n",
    "\n",
    "    Returns:\n",
    "        (X, Y): tuple of input and output arrays\n",
    "    \"\"\"\n",
    "\n",
    "    windows = list(df.rolling(window=window_size))\n",
    "    for i in windows[window_size-1:]:    \n",
    "        # split into X and Y\n",
    "        temp = i.to_numpy()\n",
    "        temp = [item for sublist in temp for item in sublist]\n",
    "        Y.append(temp.pop(-1))\n",
    "        X.append(temp)\n",
    "    return None\n",
    "\n",
    "\n",
    "def cross_validate(X, Y):\n",
    "    \"\"\"Creates a timesseries split and calculates \n",
    "    cross validation error fitted on a given estimator\n",
    "\n",
    "    Args:\n",
    "        X (array): input array \n",
    "        Y (array): output array\n",
    "        estimator (sklearn_model): Tree based machine learning model\n",
    "\n",
    "    Returns:\n",
    "        accuracies (list): list of cross validation accuracies\n",
    "    \"\"\"\n",
    "    mse = []\n",
    "    ts = TimeSeriesSplit(gap=10, max_train_size=None, n_splits=5, test_size=None)\n",
    "\n",
    "    for train_index, test_index in ts.split(X):\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = Y[train_index], Y[test_index]\n",
    "        \n",
    "        clf = linear_model.LinearRegression()\n",
    "        clf = clf.fit(X_train, y_train)\n",
    "        y_pred = clf.predict(X_test)\n",
    "        \n",
    "\n",
    "        error = mean_squared_error(y_test, y_pred)\n",
    "        mse.append(error)\n",
    "        \n",
    "    return mse, r2_score(y_test, y_pred), mean_absolute_error(y_test, y_pred)\n",
    "\n",
    "        \n",
    "    \n",
    "# Remove timezone information\n",
    "def remove_timezone(dt):\n",
    "    return dt.replace(tzinfo=None)\n",
    " \n",
    "df_data['case REG_DATE'] = df_data['case REG_DATE'].apply(remove_timezone)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(df_data[['case AMOUNT_REQ']])\n",
    "df_data['case AMOUNT_REQ'] = scaler.transform(df_data[['case AMOUNT_REQ']])\n",
    "\n",
    "# Get dummy variables and encode lifecycle\n",
    "df_dummies_lifecycle = pd.get_dummies(df_data['event lifecycle:transition'], prefix='Lifecycle', drop_first=True)\n",
    "df_data = df_data.loc[:, df_data.columns != 'event lifecycle:transition'].copy().join(df_dummies_lifecycle)\n",
    "\n",
    "\n",
    "# dummy variables encoded\n",
    "df_dummies_name = pd.get_dummies(df_data['event concept:name'], prefix='Event Name', drop_first=True)\n",
    "df_data.drop('event concept:name', axis=1, inplace=True)\n",
    "df_data = df_data.join(df_dummies_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature engineering (I think?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate time difference between current and next row\n",
    "df_data['time_diff'] = df_data['event time:timestamp'].shift(-1);\n",
    "df_data['time_diff'] = df_data['time_diff'] - df_data['event time:timestamp'] \n",
    "df_data['time_diff'] = df_data['time_diff'].dt.total_seconds();\n",
    "# df_data['time_diff'] = df_data['time_diff'].round();\n",
    "df_data = df_data.iloc[:-1];\n",
    "\n",
    "# Filter outliers\n",
    "# df_data.loc[df_data['time_diff']>600, 'time_diff'] = 601\n",
    "df_data = df_data[df_data['time_diff']<=600]\n",
    "\n",
    "# Calculate time difference since case start\n",
    "df_data['case REG_DATE'] = df_data['case REG_DATE'].apply(remove_timezone);\n",
    "df_data['days_since_start'] = df_data['event time:timestamp'] - df_data['case REG_DATE'];\n",
    "df_data['days_since_start'] = df_data['days_since_start'].dt.days;\n",
    "df_data = df_data.iloc[:-1];\n",
    "\n",
    "# Adding time features\n",
    "# df_data['day'] = df_data['event time:timestamp'].dt.day;\n",
    "# df_data['month'] = df_data['event time:timestamp'].dt.month;\n",
    "df_data['hour'] = df_data['event time:timestamp'].dt.hour;\n",
    "df_data['day_of_week'] = df_data['event time:timestamp'].dt.weekday;\n",
    "\n",
    "# Cyclical encoding\n",
    "df_data[\"hour\"] = 2 * math.pi * df_data[\"hour\"] / df_data[\"hour\"].max()\n",
    "df_data[\"hour_cos\"] = np.cos(df_data[\"hour\"])\n",
    "df_data[\"hour_sin\"] = np.sin(df_data[\"hour\"])\n",
    "df_data[\"day_of_week\"] = 2 * math.pi * df_data[\"day_of_week\"] / df_data[\"day_of_week\"].max()\n",
    "df_data[\"day_of_week_cos\"] = np.cos(df_data[\"day_of_week\"])\n",
    "df_data[\"day_of_week_sin\"] = np.sin(df_data[\"day_of_week\"])\n",
    "\n",
    "# drop unnecessary columns\n",
    "df_data.drop(columns=['event time:timestamp', 'eventID', 'case REG_DATE', 'day_of_week', 'hour'], inplace=True)\n",
    "\n",
    "# put columns in right order\n",
    "cols = df_data.columns.tolist()\n",
    "cols.remove('time_diff')\n",
    "cols = cols + ['time_diff']\n",
    "df_data = df_data[cols]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = []\n",
    "Y = []\n",
    "window = 5\n",
    "\n",
    "traces = [df_data[df_data['case concept:name']==i] for i in df_data['case concept:name'].unique() if len(df_data[df_data['case concept:name']==i])>window]\n",
    "traces = [df.drop(columns='case concept:name') for df in traces]\n",
    "temp = [sliding_window(window, i) for i in traces]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X, Y = sliding_window(5)\n",
    "test = cross_validate(np.array(X), np.array(Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mse: 1865.4181618256139\n",
      "r^2: 0.11378285321145098\n",
      "rmse: 43.19048693665787\n",
      "mae:23.91964055094481\n"
     ]
    }
   ],
   "source": [
    "print(f'mse: {np.mean(test[0])}\\nr^2: {test[1]}\\nrmse: {np.sqrt(np.mean(test[0]))}\\nmae:{test[2]}')\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
