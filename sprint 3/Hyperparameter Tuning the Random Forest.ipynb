{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "897a7ca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import psutil\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "mpl.rc('axes', labelsize=14)\n",
    "mpl.rc('xtick', labelsize=12)\n",
    "mpl.rc('ytick', labelsize=12)\n",
    "plt.rcParams[\"figure.figsize\"] = [16, 11]\n",
    "plt.rcParams[\"figure.autolayout\"] = True\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n",
    "from sklearn.model_selection import RandomizedSearchCV\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "65d079c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_split(df):\n",
    "    \"\"\"returns 10% of the data\"\"\"\n",
    "    return df[: int((len(df)/10))]\n",
    "\n",
    "\n",
    "def EventTime(data):\n",
    "    \n",
    "    for i in list(data[\"case concept:name\"].unique()):\n",
    "        data.loc[data[\"case concept:name\"] == i, \"nextTIME\"] = data.loc[data[\"case concept:name\"] == i, \n",
    "                                                                \"event time:timestamp\"].shift(-1)\n",
    "    return data\n",
    "\n",
    "\n",
    "def next_event(data, lst, case, nxt, name):\n",
    "    \"\"\"function to add the next event of a trace\"\"\"\n",
    "    for i in lst:\n",
    "        data.loc[data[case] == i, nxt] = data.loc[data[case] == i, name].shift(-1)\n",
    "    return data\n",
    "\n",
    "def prev_event(data, lst, case, prv, name):\n",
    "    \"\"\"function to add the next event of a trace\"\"\"\n",
    "    for i in lst:\n",
    "        data.loc[data[case] == i, prv] = data.loc[data[case] == i, name].shift(1)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cd4b324b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('BPI_Challenge_2012-training.csv')\n",
    "df_test = pd.read_csv('BPI_Challenge_2012-test.csv')\n",
    "df_data = pd.concat([df_train, df_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "32df521a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the data to 10% of total data, to help with runtime for demo\n",
    "df_data = data_split(df_data)\n",
    "\n",
    "pd.set_option('display.float_format', lambda x: '%.3f' % x)\n",
    "unixTransform = lambda x: time.mktime(x.timetuple())\n",
    "secondsTransform = lambda x: x.total_seconds()\n",
    "\n",
    "df_data[\"timestamp\"] = df_data[\"event time:timestamp\"].copy()\n",
    "df_data[\"event time:timestamp\"] = pd.to_datetime(df_data[\"event time:timestamp\"], dayfirst=True)\n",
    "\n",
    "df_data.sort_values(by=['event time:timestamp'], inplace=True)\n",
    "df_data.columns = df_data.columns.str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a780b3ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# assign long column names to variables for easier use\n",
    "cases = \"case concept:name\"\n",
    "reg_date = \"case REG_DATE\"\n",
    "amount_req = \"case AMOUNT_REQ\"\n",
    "event_name = \"event concept:name\"\n",
    "lifecycle = \"event lifecycle:transition\"\n",
    "tmstmp = \"event time:timestamp\"\n",
    "nxt_event = \"next event\"\n",
    "prv_event = 'previous event'\n",
    "dtime = \"delta time\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "70c8cb45",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_complete = df_data[df_data[lifecycle] == df_data[lifecycle].unique()[0]].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b68ff510",
   "metadata": {},
   "outputs": [],
   "source": [
    "lst_events = df_complete[cases].unique().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f83730c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add next events per trace\n",
    "next_event(df_complete, lst_events, cases, nxt_event, event_name);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d4d5073d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add time till next event per trace\n",
    "EventTime(df_complete);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "521a550b",
   "metadata": {},
   "outputs": [],
   "source": [
    "prev_event(df_complete, lst_events, cases, prv_event, event_name);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4fbe7f3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_processed = df_complete.drop([lifecycle], axis=1).copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ebd75ad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "event_encoder = LabelEncoder()\n",
    "time_of_day_encoder = OrdinalEncoder()\n",
    "\n",
    "labels = df_processed[event_name].unique()\n",
    "event_encoder.fit(labels);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b7031492",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_processed['time of day'] = df_processed[\"timestamp\"].str.split(expand=True)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d5615497",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_processed[[event_name, nxt_event, prv_event]] = df_processed[[event_name, nxt_event, prv_event]].apply(event_encoder.fit_transform)\n",
    "df_processed[\"time of day\"] = time_of_day_encoder.fit_transform(df_processed[[\"time of day\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3e704a79",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_processed[[amount_req, event_name, prv_event]]\n",
    "y = df_processed[nxt_event]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b258b77d",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e484eba6",
   "metadata": {},
   "source": [
    "# Random Hyperparameter Grid"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92feefb9",
   "metadata": {},
   "source": [
    "### https://towardsdatascience.com/hyperparameter-tuning-the-random-forest-in-python-using-scikit-learn-28d2aa77dd74"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a95e1498",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_estimators = [int(x) for x in np.linspace(start = 200, stop = 2000, num = 10)]\n",
    "# Number of features to consider at every split\n",
    "max_features = ['auto', 'sqrt']\n",
    "# Maximum number of levels in tree\n",
    "max_depth = [int(x) for x in np.linspace(10, 110, num = 11)]\n",
    "max_depth.append(None)\n",
    "# Minimum number of samples required to split a node\n",
    "min_samples_split = [2, 5, 10]\n",
    "# Minimum number of samples required at each leaf node\n",
    "min_samples_leaf = [1, 2, 4]\n",
    "# Method of selecting samples for training each tree\n",
    "bootstrap = [True, False]# Create the random grid\n",
    "random_grid = {'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf,\n",
    "               'bootstrap': bootstrap}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "a44624fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 100 candidates, totalling 300 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=3, estimator=RandomForestClassifier(), n_iter=100,\n",
       "                   n_jobs=-1,\n",
       "                   param_distributions={'bootstrap': [True, False],\n",
       "                                        'max_depth': [10, 20, 30, 40, 50, 60,\n",
       "                                                      70, 80, 90, 100, 110,\n",
       "                                                      None],\n",
       "                                        'max_features': ['auto', 'sqrt'],\n",
       "                                        'min_samples_leaf': [1, 2, 4],\n",
       "                                        'min_samples_split': [2, 5, 10],\n",
       "                                        'n_estimators': [200, 400, 600, 800,\n",
       "                                                         1000, 1200, 1400, 1600,\n",
       "                                                         1800, 2000]},\n",
       "                   random_state=42, verbose=2)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use the random grid to search for best hyperparameters\n",
    "# First create the base model to tune\n",
    "rf = RandomForestClassifier()\n",
    "# Random search of parameters, using 3 fold cross validation, \n",
    "# search across 100 different combinations, and use all available cores\n",
    "rf_random = RandomizedSearchCV(estimator = rf, param_distributions = random_grid, n_iter = 100, cv = 3, verbose=2, random_state=42, n_jobs = -1)# Fit the random search model\n",
    "rf_random.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "cac7c72a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_estimators': 1600,\n",
       " 'min_samples_split': 5,\n",
       " 'min_samples_leaf': 1,\n",
       " 'max_features': 'auto',\n",
       " 'max_depth': 10,\n",
       " 'bootstrap': True}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_random.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9cf16456",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, test_features, test_labels):\n",
    "    y_pred = model.predict(x_test)\n",
    "    prec_score = precision_score(y_test, y_pred, average=\"weighted\", zero_division=0)\n",
    "    rec_score = recall_score(y_test, y_pred, average=\"weighted\", zero_division=0)\n",
    "    F1_score = f1_score(y_test, y_pred, average=\"weighted\", zero_division=0)\n",
    "    acc_score = accuracy_score(y_test, y_pred)\n",
    "\n",
    "    print(f'The accuracy of the model is {acc_score}.')\n",
    "    print(f'The precision of the model is {prec_score}, using weighted average.')\n",
    "    print(f'The recall of the model is {rec_score}, using weighted average.')\n",
    "    print(f'The f1-score of the model is {F1_score}, using weighted average.')\n",
    "    \n",
    "    return acc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a099bd1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy of the model is 0.6488563259471051.\n",
      "The precision of the model is 0.6554693616434675, using weighted average.\n",
      "The recall of the model is 0.6488563259471051, using weighted average.\n",
      "The f1-score of the model is 0.6209804992585465, using weighted average.\n"
     ]
    }
   ],
   "source": [
    "base_model = RandomForestClassifier(n_estimators = 10, random_state = 42)\n",
    "base_model.fit(x_train, y_train)\n",
    "base_accuracy = evaluate(base_model, x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "eda22a93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy of the model is 0.6588634739099357.\n",
      "The precision of the model is 0.6662702949725373, using weighted average.\n",
      "The recall of the model is 0.6588634739099357, using weighted average.\n",
      "The f1-score of the model is 0.613446793399547, using weighted average.\n"
     ]
    }
   ],
   "source": [
    "best_random = rf_random.best_estimator_\n",
    "random_accuracy = evaluate(best_random, x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "c871e450",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Improvement of 1.54%.\n"
     ]
    }
   ],
   "source": [
    "print('Improvement of {:0.2f}%.'.format( 100 * (random_accuracy - base_accuracy) / base_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "7a39fdd4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.0385619 , 0.45269283, 0.50874527])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_random.feature_importances_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbe90b90",
   "metadata": {},
   "source": [
    "# Grid Search with Cross Validation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "39e57bb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the parameter grid based on the results of random search \n",
    "param_grid = {\n",
    "    'bootstrap': [True],\n",
    "    'max_depth': [1, 10, 15, 20],\n",
    "    'max_features': [2, 3],\n",
    "    'min_samples_leaf': [1, 2, 3],\n",
    "    'min_samples_split': [3, 5, 10],\n",
    "    'n_estimators': [100, 1400, 1600, 2000]\n",
    "}# Create a based model\n",
    "rf = RandomForestClassifier()# Instantiate the grid search model\n",
    "grid_search = GridSearchCV(estimator = rf, param_grid = param_grid, \n",
    "                          cv = 3, n_jobs = -1, verbose = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "608cbf81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 288 candidates, totalling 864 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'bootstrap': True,\n",
       " 'max_depth': 10,\n",
       " 'max_features': 2,\n",
       " 'min_samples_leaf': 1,\n",
       " 'min_samples_split': 10,\n",
       " 'n_estimators': 2000}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the grid search to the data\n",
    "grid_search.fit(x_train, y_train)\n",
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d9dd2155",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy of the model is 0.6767333809864189.\n",
      "The precision of the model is 0.6785113784560418, using weighted average.\n",
      "The recall of the model is 0.6767333809864189, using weighted average.\n",
      "The f1-score of the model is 0.6373846895148406, using weighted average.\n"
     ]
    }
   ],
   "source": [
    "best_grid = grid_search.best_estimator_\n",
    "grid_accuracy = evaluate(best_grid, x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3225f1d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Improvement of 4.30%.\n"
     ]
    }
   ],
   "source": [
    "print('Improvement of {:0.2f}%.'.format( 100 * (grid_accuracy - base_accuracy) / base_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "61ad3199",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.05971821, 0.4454768 , 0.49480499])"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_grid.feature_importances_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a52bd06",
   "metadata": {},
   "source": [
    "# Grid V2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b5b3d98",
   "metadata": {},
   "source": [
    "### https://towardsdatascience.com/optimizing-hyperparameters-in-random-forest-classification-ec7741f9d3f6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "dcc1f1fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the parameter grid based on the results of random search \n",
    "param_grid = {\n",
    "    'bootstrap': [True],\n",
    "    'max_depth': [5, 8, 15, 25, 30],\n",
    "    'max_features': [2, 3],\n",
    "    'min_samples_leaf': [1, 2, 5, 10],\n",
    "    'min_samples_split': [2, 5, 10, 15, 100],\n",
    "    'n_estimators': [100, 300, 500, 800, 1200]\n",
    "}\n",
    "rf = RandomForestClassifier()# Instantiate the grid search model\n",
    "grid_search2 = GridSearchCV(estimator = rf, param_grid = param_grid, \n",
    "                          cv = 3, n_jobs = -1, verbose = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ef69d63f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 1000 candidates, totalling 3000 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'bootstrap': True,\n",
       " 'max_depth': 8,\n",
       " 'max_features': 2,\n",
       " 'min_samples_leaf': 1,\n",
       " 'min_samples_split': 15,\n",
       " 'n_estimators': 1200}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the grid search to the data\n",
    "grid_search2.fit(x_train, y_train)\n",
    "grid_search2.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "28eff6f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy of the model is 0.672265904217298.\n",
      "The precision of the model is 0.6751476704278561, using weighted average.\n",
      "The recall of the model is 0.672265904217298, using weighted average.\n",
      "The f1-score of the model is 0.6285485501309177, using weighted average.\n"
     ]
    }
   ],
   "source": [
    "best_grid2 = grid_search2.best_estimator_\n",
    "grid_accuracy2 = evaluate(best_grid2, x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6812419e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Improvement of 3.61%.\n"
     ]
    }
   ],
   "source": [
    "print('Improvement of {:0.2f}%.'.format( 100 * (grid_accuracy2 - base_accuracy) / base_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df355ac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_grid2.feature_importances_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f2627dd",
   "metadata": {},
   "source": [
    "### As we can see from the results the improvement is really small, considering the time it needs to run, I think it is not worth our time. \n",
    "\"Hyperparameter tuning can be advantageous in creating a model that is better at classification. In the case of a random forest, it may not be necessary, as random forests are already very good at classification. \""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
