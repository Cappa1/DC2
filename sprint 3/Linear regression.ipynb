{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn import linear_model\n",
    "import math\n",
    "\n",
    "np.set_printoptions(formatter={'float_kind':'{:f}'.format})\n",
    "pd.set_option('display.float_format', lambda x: '%.3f' % x)\n",
    "\n",
    "\n",
    "plt.style.use('seaborn')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading data and preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = r\"/home/dazai/Documents/Processmining/Data/\"\n",
    "df_train = pd.read_csv(f'{path}BPI_Challenge_2012-training.csv')\n",
    "df_test = pd.read_csv(f'{path}BPI_Challenge_2012-test.csv')\n",
    "\n",
    "\n",
    "df_data = pd.concat([df_train, df_test])\n",
    "df_data['event time:timestamp'] = pd.to_datetime(df_data['event time:timestamp'], dayfirst=False)\n",
    "df_data['case REG_DATE'] = pd.to_datetime(df_data['case REG_DATE'], dayfirst=True)\n",
    "\n",
    "df_data.sort_values(by=['event time:timestamp'], inplace=True)\n",
    "df_data.reset_index(inplace=True, drop=True)\n",
    "\n",
    "# remove whitespace at beginning and end of column name\n",
    "df_data.columns = df_data.columns.str.strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def sliding_window(df_data, window_size, response_variable): \n",
    "    \"\"\"Iterates over input data and creates batches \n",
    "    with variable lag based on response_variable\n",
    "\n",
    "    Args:\n",
    "        df_data (dataframe): input dataframe\n",
    "        window_size (int): amount of lags\n",
    "        response_variable (str): column we want to predict\n",
    "\n",
    "    Returns:\n",
    "        (X, Y) (tuple): tuple of arrays transformed using sliding window\n",
    "    \"\"\"\n",
    "    start = 0\n",
    "    X = []\n",
    "    Y = []\n",
    "\n",
    "    for i in range(len(df_data)):\n",
    "        if i >= window_size:\n",
    "            window = df_data.iloc[start:i+1]\n",
    "            temp = window.iloc[:window_size].to_numpy()\n",
    "            X.append([item for sublist in temp for item in sublist])\n",
    "            Y.append(window.iloc[-1][response_variable])\n",
    "            start +=1\n",
    "            \n",
    "    return np.array(X), np.array(Y)\n",
    "\n",
    "\n",
    "def cross_validate(X, Y):\n",
    "    \"\"\"Creates a timesseries split and calculates \n",
    "    cross validation error fitted on a given estimator\n",
    "\n",
    "    Args:\n",
    "        X (array): input array \n",
    "        Y (array): output array\n",
    "        estimator (sklearn_model): Tree based machine learning model\n",
    "\n",
    "    Returns:\n",
    "        accuracies (list): list of cross validation accuracies\n",
    "    \"\"\"\n",
    "    ts = TimeSeriesSplit(gap=10, max_train_size=None, n_splits=5, test_size=None)\n",
    "    \n",
    "    errors = []\n",
    "\n",
    "    for train_index, test_index in ts.split(X):\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = Y[train_index], Y[test_index]\n",
    "        \n",
    "        clf = linear_model.LinearRegression()\n",
    "        clf = clf.fit(X_train, y_train)\n",
    "        y_pred = clf.predict(X_test)\n",
    "        \n",
    "\n",
    "        mse = mean_squared_error(y_test, y_pred)\n",
    "        errors.append(mse)\n",
    "    return errors\n",
    "\n",
    "        \n",
    "    \n",
    "# Remove timezone information\n",
    "def remove_timezone(dt):\n",
    "    return dt.replace(tzinfo=None)\n",
    " \n",
    "df_data['case REG_DATE'] = df_data['case REG_DATE'].apply(remove_timezone)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(df_data[['case AMOUNT_REQ']])\n",
    "df_data['case AMOUNT_REQ'] = scaler.transform(df_data[['case AMOUNT_REQ']])\n",
    "\n",
    "# Get dummy variables and encode lifecycle\n",
    "df_dummies_lifecycle = pd.get_dummies(df_data['event lifecycle:transition'], prefix='Lifecycle', drop_first=True)\n",
    "df_data = df_data.loc[:, df_data.columns != 'event lifecycle:transition'].copy().join(df_dummies_lifecycle)\n",
    "\n",
    "\n",
    "# dummy variables encoded\n",
    "df_dummies_name = pd.get_dummies(df_data['event concept:name'], prefix='Event Name', drop_first=True)\n",
    "df_data.drop('event concept:name', axis=1, inplace=True)\n",
    "\n",
    "# adding encoded values \n",
    "df_data = df_data.join(df_dummies_name)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature engineering (I think?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate time difference between current and next row\n",
    "df_data['time_diff'] = df_data['event time:timestamp'].shift(1);\n",
    "df_data['time_diff'] = df_data['event time:timestamp'] - df_data['time_diff']\n",
    "df_data['time_diff'] = df_data['time_diff'].dt.total_seconds();\n",
    "df_data['time_diff'] = df_data['time_diff'].round();\n",
    "df_data = df_data.iloc[1:];\n",
    "\n",
    "# Filter outliers\n",
    "df_data.loc[df_data['time_diff']>600, 'time_diff'] = 601\n",
    "\n",
    "\n",
    "# Calculate time difference since case start\n",
    "df_data['case REG_DATE'] = df_data['case REG_DATE'].apply(remove_timezone);\n",
    "df_data['days_since_start'] = df_data['event time:timestamp'] - df_data['case REG_DATE'];\n",
    "df_data['days_since_start'] = df_data['days_since_start'].dt.days;\n",
    "df_data = df_data.iloc[:-1];\n",
    "\n",
    "# Adding time features\n",
    "df_data['day'] = df_data['event time:timestamp'].dt.day;\n",
    "df_data['month'] = df_data['event time:timestamp'].dt.month;\n",
    "df_data['hour'] = df_data['event time:timestamp'].dt.hour;\n",
    "df_data['day_of_week'] = df_data['event time:timestamp'].dt.weekday;\n",
    "\n",
    "\n",
    "# Cyclical encoding\n",
    "df_data[\"hour\"] = 2 * math.pi * df_data[\"hour\"] / df_data[\"hour\"].max()\n",
    "df_data[\"hour_cos\"] = np.cos(df_data[\"hour\"])\n",
    "df_data[\"hour_sin\"] = np.sin(df_data[\"hour\"])\n",
    "df_data.drop(columns='hour', inplace=True)\n",
    "\n",
    "df_data[\"day_of_week\"] = 2 * math.pi * df_data[\"day_of_week\"] / df_data[\"day_of_week\"].max()\n",
    "df_data[\"day_of_week_cos\"] = np.cos(df_data[\"day_of_week\"])\n",
    "df_data[\"day_of_week_sin\"] = np.sin(df_data[\"day_of_week\"])\n",
    "\n",
    "# drop columns\n",
    "df_data.drop(columns=['event time:timestamp', 'eventID', 'case concept:name', 'case REG_DATE', 'day_of_week'], inplace=True)\n",
    "\n",
    "\n",
    "# scaling like this is illegal I think\n",
    "# scaler = MinMaxScaler()\n",
    "# scaler.fit(df_time[['time_diff']])\n",
    "# df_time['time_diff'] = scaler.transform(df_time[['time_diff']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts = TimeSeriesSplit(gap=10, max_train_size=None, n_splits=5, test_size=None)\n",
    "X, Y = sliding_window(df_data, 3, 'time_diff')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[6300.7285509034455,\n",
       " 4252.79408801197,\n",
       " 3757.6789322486525,\n",
       " 3225.5922997606585,\n",
       " 5218.085392732982]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_validate(X,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
