{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn import linear_model\n",
    "import math\n",
    "\n",
    "np.set_printoptions(formatter={'float_kind':'{:f}'.format})\n",
    "pd.set_option('display.float_format', lambda x: '%.3f' % x)\n",
    "plt.style.use('seaborn')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading data and preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data = pd.read_pickle('/home/dazai/Documents/Processmining/Data/pickle.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uncomment the cell below and run it if you dont have a pickle of preprocessed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path = r\"/home/dazai/Documents/Processmining/Data/\"\n",
    "# df_train = pd.read_csv(f'{path}BPI_Challenge_2012-training.csv')\n",
    "# df_test = pd.read_csv(f'{path}BPI_Challenge_2012-test.csv')\n",
    "\n",
    "\n",
    "# df_data = pd.concat([df_train, df_test])\n",
    "# df_data['event time:timestamp'] = pd.to_datetime(df_data['event time:timestamp'], dayfirst=True)\n",
    "# df_data['case REG_DATE'] = pd.to_datetime(df_data['case REG_DATE'])\n",
    "\n",
    "# df_data.sort_values(by=['event time:timestamp'], inplace=True)\n",
    "# df_data.reset_index(inplace=True, drop=True)\n",
    "\n",
    "# # remove whitespace at beginning and end of column name\n",
    "# df_data.columns = df_data.columns.str.strip(' ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sliding_window(window_size):\n",
    "    \"\"\"transforms df_data into supervised form \n",
    "    with rolling window implementations\n",
    "\n",
    "    Args:\n",
    "        window_size (int): size of rolling window\n",
    "\n",
    "    Returns:\n",
    "        (X, Y): tuple of input and output arrays\n",
    "    \"\"\"\n",
    "    X = []\n",
    "    Y = []\n",
    "\n",
    "    windows = list(df_data.rolling(window=window_size))\n",
    "    for i in windows[window_size-1:]:    \n",
    "        # split into X and Y\n",
    "        temp = i.to_numpy()\n",
    "        temp = [item for sublist in temp for item in sublist]\n",
    "        Y.append(temp.pop(-1))\n",
    "        X.append(temp)\n",
    "    return np.array(X), np.array(Y)\n",
    "\n",
    "\n",
    "def cross_validate(X, Y):\n",
    "    \"\"\"Creates a timesseries split and calculates \n",
    "    cross validation error fitted on a given estimator\n",
    "\n",
    "    Args:\n",
    "        X (array): input array \n",
    "        Y (array): output array\n",
    "        estimator (sklearn_model): Tree based machine learning model\n",
    "\n",
    "    Returns:\n",
    "        accuracies (list): list of cross validation accuracies\n",
    "    \"\"\"\n",
    "    errors = []\n",
    "    ts = TimeSeriesSplit(gap=10, max_train_size=None, n_splits=5, test_size=None)\n",
    "\n",
    "    for train_index, test_index in ts.split(X):\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = Y[train_index], Y[test_index]\n",
    "        \n",
    "        clf = linear_model.LinearRegression()\n",
    "        clf = clf.fit(X_train, y_train)\n",
    "        y_pred = clf.predict(X_test)\n",
    "        \n",
    "\n",
    "        mse = mean_squared_error(y_test, y_pred)\n",
    "        errors.append(mse)\n",
    "    return errors\n",
    "\n",
    "        \n",
    "    \n",
    "# Remove timezone information\n",
    "def remove_timezone(dt):\n",
    "    return dt.replace(tzinfo=None)\n",
    " \n",
    "df_data['case REG_DATE'] = df_data['case REG_DATE'].apply(remove_timezone)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(df_data[['case AMOUNT_REQ']])\n",
    "df_data['case AMOUNT_REQ'] = scaler.transform(df_data[['case AMOUNT_REQ']])\n",
    "\n",
    "# Get dummy variables and encode lifecycle\n",
    "df_dummies_lifecycle = pd.get_dummies(df_data['event lifecycle:transition'], prefix='Lifecycle', drop_first=True)\n",
    "df_data = df_data.loc[:, df_data.columns != 'event lifecycle:transition'].copy().join(df_dummies_lifecycle)\n",
    "\n",
    "\n",
    "# dummy variables encoded\n",
    "df_dummies_name = pd.get_dummies(df_data['event concept:name'], prefix='Event Name', drop_first=True)\n",
    "df_data.drop('event concept:name', axis=1, inplace=True)\n",
    "df_data = df_data.join(df_dummies_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature engineering (I think?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate time difference between current and next row\n",
    "df_data['time_diff'] = df_data['event time:timestamp'].shift(-1);\n",
    "df_data['time_diff'] = df_data['time_diff'] - df_data['event time:timestamp'] \n",
    "df_data['time_diff'] = df_data['time_diff'].dt.total_seconds();\n",
    "# df_data['time_diff'] = df_data['time_diff'].round();\n",
    "df_data = df_data.iloc[:-1];\n",
    "\n",
    "# Filter outliers\n",
    "# df_data.loc[df_data['time_diff']>600, 'time_diff'] = 601\n",
    "df_data = df_data[df_data['time_diff']<=600]\n",
    "\n",
    "# Calculate time difference since case start\n",
    "df_data['case REG_DATE'] = df_data['case REG_DATE'].apply(remove_timezone);\n",
    "df_data['days_since_start'] = df_data['event time:timestamp'] - df_data['case REG_DATE'];\n",
    "df_data['days_since_start'] = df_data['days_since_start'].dt.days;\n",
    "df_data = df_data.iloc[:-1];\n",
    "\n",
    "# Adding time features\n",
    "df_data['day'] = df_data['event time:timestamp'].dt.day;\n",
    "df_data['month'] = df_data['event time:timestamp'].dt.month;\n",
    "df_data['hour'] = df_data['event time:timestamp'].dt.hour;\n",
    "df_data['day_of_week'] = df_data['event time:timestamp'].dt.weekday;\n",
    "\n",
    "# Cyclical encoding\n",
    "df_data[\"hour\"] = 2 * math.pi * df_data[\"hour\"] / df_data[\"hour\"].max()\n",
    "df_data[\"hour_cos\"] = np.cos(df_data[\"hour\"])\n",
    "df_data[\"hour_sin\"] = np.sin(df_data[\"hour\"])\n",
    "df_data[\"day_of_week\"] = 2 * math.pi * df_data[\"day_of_week\"] / df_data[\"day_of_week\"].max()\n",
    "df_data[\"day_of_week_cos\"] = np.cos(df_data[\"day_of_week\"])\n",
    "df_data[\"day_of_week_sin\"] = np.sin(df_data[\"day_of_week\"])\n",
    "\n",
    "# drop unnecessary columns\n",
    "df_data.drop(columns=['event time:timestamp', 'eventID', 'case concept:name', 'case REG_DATE', 'day_of_week', 'hour'], inplace=True)\n",
    "\n",
    "# put columns in right order\n",
    "cols = df_data.columns.tolist()\n",
    "cols.remove('time_diff')\n",
    "cols = cols + ['time_diff']\n",
    "df_data = df_data[cols]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1892.0392908253148,\n",
       " 1993.7187287617103,\n",
       " 3685.817597814194,\n",
       " 1711.2514610945411,\n",
       " 2346.429837422544]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X, Y = sliding_window(5)\n",
    "cross_validate(X, Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results based on window_size of 5\n",
    "Mse without filtering outliers: [225325.63533256113,\n",
    " 285941.6154406469,\n",
    " 45467736.95099862,\n",
    " 216166.30340970002,\n",
    " 855288.0102282097] <br>mean: a lot <br> <br>\n",
    "Mse removed outliers : [1892.0392908253148,\n",
    " 1993.7187287617103,\n",
    " 3685.817597814194,\n",
    " 1711.2514610945411,\n",
    " 2346.429837422544] <br>mean: 2325.851383183661<br><br>\n",
    "Mse with capped outliers: [3884.040469677467,\n",
    " 4085.3240826743213,\n",
    " 73244.44519472372,\n",
    " 3520.115231681768,\n",
    " 4315.405208939567] <br>mean: 17809.86603753937"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.mean([1940.9284421407326,\n",
    "#  2055.2853996454674,\n",
    "#  3018.4338305175916,\n",
    "#  1752.2514213197157,\n",
    "#  2414.388346213773])\n",
    "\n",
    "\n",
    "# counter = 0\n",
    "# for i in range(100000,260000,5000):\n",
    "#     if counter < 150:\n",
    "#         display(df_data.iloc[[i]])\n",
    "#     counter += 1\n",
    "\n",
    "\n",
    "# counter = 0\n",
    "# for i in df_data[df_data['time_diff']>28800].index:\n",
    "#     if counter < 5:\n",
    "#         display(df_data.loc[i-3:i+3])\n",
    "#     counter += 1\n",
    "\n",
    "\n",
    "# def sliding_window(df_data, window_size, response_variable): \n",
    "#     \"\"\"Iterates over input data and creates batches \n",
    "#     with variable lag based on response_variable\n",
    "\n",
    "#     Args:\n",
    "#         df_data (dataframe): input dataframe\n",
    "#         window_size (int): amount of lags\n",
    "#         response_variable (str): column we want to predict\n",
    "\n",
    "#     Returns:\n",
    "#         (X, Y) (tuple): tuple of arrays transformed using sliding window\n",
    "#     \"\"\"\n",
    "#     start = 0\n",
    "#     X = []\n",
    "#     Y = []\n",
    "\n",
    "#     for i in range(len(df_data)):\n",
    "#         if i >= window_size:\n",
    "#             window = df_data.iloc[start:i+1]\n",
    "#             temp = window.iloc[:window_size].to_numpy()\n",
    "#             X.append([item for sublist in temp for item in sublist])\n",
    "#             Y.append(window.iloc[-1][response_variable])\n",
    "#             start +=1\n",
    "            \n",
    "#     return np.array(X), np.array(Y)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
