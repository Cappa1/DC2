{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "%run functions/preprocess.py\n",
    "\n",
    "np.random.seed(42)\n",
    "pd.set_option('display.float_format', lambda x: '%.3f' % x)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Time preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 13 s, sys: 1.49 s, total: 14.5 s\n",
      "Wall time: 14.5 s\n"
     ]
    }
   ],
   "source": [
    "% % time\n",
    "path = open('path.txt', 'r').read().strip()\n",
    "train = pd.read_csv(f'{path}BPI Challenge 2017-training.csv')\n",
    "test = pd.read_csv(f'{path}BPI Challenge 2017-test.csv')\n",
    "data = pd.concat([train, test])\n",
    "\n",
    "# strip whitespace of column names and add extra time columns\n",
    "data.columns = data.columns.str.strip()\n",
    "\n",
    "# remove milliseconds\n",
    "remove_ms(data)\n",
    "\n",
    "# Convert to timestamp and decompose features\n",
    "data['event time:timestamp'] = f_memoize_dt(data['event time:timestamp'])\n",
    "data['time of day'] = data['event time:timestamp'].dt.time\n",
    "data[\"weekday\"] = data[\"event time:timestamp\"].dt.day_name()\n",
    "\n",
    "# sorting values\n",
    "data.sort_values(by=['event time:timestamp'], inplace=True)\n",
    "data.reset_index(inplace=True, drop=True)\n",
    "\n",
    "# add unix time column\n",
    "UnixTime(data)\n",
    "data[\"Unix\"] = data[\"Unix\"].astype(int)\n",
    "\n",
    "# drop useless columns\n",
    "dropper(data, lbls=[\"eventID\", \"event EventID\"])\n",
    "\n",
    "\n",
    "# check if dataframe sorted\n",
    "# for i in range(0,1202267, 10000):\n",
    "#     display(df_data['event time:timestamp'].iloc[[i]])\n",
    "\n",
    "######## CHECK IF CORRECT #########\n",
    "# data[\"timestamp\"] = data[\"event time:timestamp\"].copy()\n",
    "# data[\"event time:timestamp\"] = pd.to_datetime(data[\"event time:timestamp\"], dayfirst=True)\n",
    "# data['time of day'] = data[\"timestamp\"].str.split(expand=True)[1]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Event/time adder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# event shifting\n",
    "data['next_event'] = data.groupby('case concept:name')[\n",
    "    'event concept:name'].shift(-1)\n",
    "data[\"prev_event\"] = data.groupby('case concept:name')[\n",
    "    'event concept:name'].shift(1)\n",
    "\n",
    "# time shifting\n",
    "data[\"nextUnix\"] = data.groupby('case concept:name')['Unix'].shift(-1)\n",
    "data[\"prevUnix\"] = data.groupby('case concept:name')['Unix'].shift(1)\n",
    "data[\"nextTime\"] = data.groupby('case concept:name')[\n",
    "    'event time:timestamp'].shift(-1)\n",
    "data[\"prevTime\"] = data.groupby('case concept:name')[\n",
    "    'event time:timestamp'].shift(1)\n",
    "\n",
    "# Adding time features\n",
    "data['day'] = data['event time:timestamp'].dt.day\n",
    "data['month'] = data['event time:timestamp'].dt.month\n",
    "data['hour'] = data['event time:timestamp'].dt.hour\n",
    "data['day_of_week'] = data['event time:timestamp'].dt.weekday\n",
    "\n",
    "# Cyclical encoding\n",
    "data[\"hour\"] = 2 * np.pi * data[\"hour\"] / data[\"hour\"].max()\n",
    "data[\"hour_cos\"] = np.cos(data[\"hour\"])\n",
    "data[\"hour_sin\"] = np.sin(data[\"hour\"])\n",
    "data[\"day_of_week\"] = 2 * np.pi * \\\n",
    "    data[\"day_of_week\"] / data[\"day_of_week\"].max()\n",
    "data[\"day_of_week_cos\"] = np.cos(data[\"day_of_week\"])\n",
    "data[\"day_of_week_sin\"] = np.sin(data[\"day_of_week\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(data[['case RequestedAmount']])\n",
    "data['case RequestedAmount'] = scaler.transform(data[['case RequestedAmount']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_pickle(f\"processed2017.pkl\")\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "47c473ffaad557a40d6f692199c8550b37e2966a5f36ac429a864ed95aaad2b0"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
